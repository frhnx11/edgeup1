import { useState, useEffect, useRef, useCallback, memo } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { Bot, X } from 'lucide-react';
import Lottie from 'lottie-react';
import { useLocation } from 'react-router-dom';

// Global audio tracker to manage audio across all AIVoiceAgent instances
const globalAudioTracker = {
  currentAudio: null as HTMLAudioElement | null,
  stopAll: () => {
    if (globalAudioTracker.currentAudio) {
      try {
        globalAudioTracker.currentAudio.pause();
        globalAudioTracker.currentAudio.currentTime = 0;
        globalAudioTracker.currentAudio.src = '';
        globalAudioTracker.currentAudio = null;
      } catch (e) {
      }
    }
    // Stop browser TTS
    if (window.speechSynthesis) {
      window.speechSynthesis.cancel();
      for (let i = 0; i < 10; i++) {
        setTimeout(() => window.speechSynthesis.cancel(), i * 50);
      }
    }
  }
};

interface AIVoiceAgentProps {
  message: string;
  autoPlay?: boolean;
  position?: 'bottom-right' | 'bottom-left' | 'top-right' | 'top-left';
  onComplete?: () => void;
}

export const AIVoiceAgent = memo(function AIVoiceAgent({
  message,
  autoPlay = true,
  position = 'bottom-right',
  onComplete
}: AIVoiceAgentProps) {
  console.log('üé§üé§üé§ AIVoiceAgent v4.0 AUTO-PLAY ENABLED: Component rendered with message:', message.substring(0, 50) + '...');
  console.log('üé§üé§üé§ AIVoiceAgent v4.0 AUTO-PLAY ENABLED: autoPlay:', autoPlay, 'position:', position);
  console.log('üé§üé§üé§ AIVoiceAgent v4.0 AUTO-PLAY ENABLED: Timestamp:', new Date().toISOString());
  console.log('üé§üé§üé§ AIVoiceAgent v4.0: ONLY ELEVENLABS AUDIO - NO PRE-RECORDED AUDIO!');

  const location = useLocation();
  const [isPlaying, setIsPlaying] = useState(false);
  const [isVisible, setIsVisible] = useState(true);
  const [hasPlayed, setHasPlayed] = useState(false);
  const [showTooltip, setShowTooltip] = useState(false);
  const lottieRef = useRef<any>(null);
  const [animationData, setAnimationData] = useState<any>(null);
  const [currentText, setCurrentText] = useState('');
  const [wordIndex, setWordIndex] = useState(0);
  const [isLoading, setIsLoading] = useState(false);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const transcriptionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const intentionalStopRef = useRef(false);
  const browserUtteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const isInitializingRef = useRef(false); // Prevent duplicate audio initialization
  const audioInstanceIdRef = useRef(0); // Track audio instances to prevent zombie audio

  const words = message.split(' ');

  // Debug: Track component mount and state

  // Function to trigger Lottie animation
  const triggerLottieAnimation = (play: boolean) => {
    if (lottieRef.current) {
      try {
        if (play) {
          lottieRef.current.play();
        } else {
          lottieRef.current.pause();
        }
      } catch (err) {
      }
    }
  };

  // Position classes - adjusted for better spacing
  const positionClasses = {
    'bottom-right': 'bottom-6 right-6',
    'bottom-left': 'bottom-6 left-6',
    'top-right': 'top-40 right-6',  // More space from top for transcription box
    'top-left': 'top-40 left-6'     // More space from top for transcription box
  };

  // Stop all audio playback
  const stopAudio = () => {

    // Mark as intentional stop to prevent fallback
    intentionalStopRef.current = true;
    isInitializingRef.current = false; // Reset initialization flag
    audioInstanceIdRef.current++; // Invalidate any in-flight audio

    // Stop global audio first
    globalAudioTracker.stopAll();

    // Stop local ElevenLabs audio
    if (audioRef.current) {
      try {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
        audioRef.current.src = '';
        audioRef.current.load(); // Force stop loading
        audioRef.current = null;
      } catch (e) {
      }
    }

    // Stop browser TTS - force multiple cancels to ensure it stops
    if (window.speechSynthesis) {
      window.speechSynthesis.cancel();
      // Keep canceling multiple times to ensure it stops
      for (let i = 0; i < 5; i++) {
        setTimeout(() => {
          if (window.speechSynthesis.speaking) {
            window.speechSynthesis.cancel();
          }
        }, i * 50);
      }
    }

    // Clear transcription interval
    if (transcriptionIntervalRef.current) {
      clearInterval(transcriptionIntervalRef.current);
      transcriptionIntervalRef.current = null;
    }

    // Reset state
    setIsPlaying(false);
    setIsLoading(false);
    setCurrentText('');
    setWordIndex(0);
    triggerLottieAnimation(false);
  };

  // Synthesize speech using ElevenLabs API with your cloned voice
  const synthesizeSpeechElevenLabs = async (text: string) => {
    console.log('üé§ AIVoiceAgent: synthesizeSpeechElevenLabs called with text:', text);

    // Prevent duplicate audio initialization
    if (isInitializingRef.current) {
      console.log('üé§ AIVoiceAgent: Already initializing, skipping...');
      return false;
    }

    const apiKey = import.meta.env.VITE_ELEVENLABS_API_KEY;
    console.log('üé§ AIVoiceAgent: API Key exists:', !!apiKey);

    if (!apiKey) {
      console.log('üé§ AIVoiceAgent: No API key, falling back to browser TTS');
      return synthesizeSpeechBrowser(text);
    }

    try {
      console.log('üé§ AIVoiceAgent: Starting ElevenLabs synthesis...');
      isInitializingRef.current = true; // Mark as initializing

      // Increment and capture the instance ID for this audio
      audioInstanceIdRef.current++;
      const currentInstanceId = audioInstanceIdRef.current;

      const voiceId = '6M2vBUD6JYB8KsxhAMph'; // Your cloned voice ID

      // Reset intentional stop flag when starting new audio
      intentionalStopRef.current = false;

      // CRITICAL: Stop any existing audio before creating new one
      if (audioRef.current) {
        try {
          audioRef.current.pause();
          audioRef.current.currentTime = 0;
          audioRef.current.src = '';
          audioRef.current = null;
        } catch (e) {
        }
      }

      // IMPORTANT: Stop any existing browser TTS before starting ElevenLabs
      if (window.speechSynthesis) {
        window.speechSynthesis.cancel();
        // Force cancel multiple times to ensure it stops
        setTimeout(() => window.speechSynthesis.cancel(), 10);
        setTimeout(() => window.speechSynthesis.cancel(), 50);
        setTimeout(() => window.speechSynthesis.cancel(), 100);
      }

      setIsLoading(true);
      setCurrentText('Loading...');
      setWordIndex(0);

      // Make API call to ElevenLabs with optimized settings for speed
      const response = await fetch(`https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`, {
        method: 'POST',
        headers: {
          'Accept': 'audio/mpeg',
          'Content-Type': 'application/json',
          'xi-api-key': apiKey
        },
        body: JSON.stringify({
          text: text,
          model_id: 'eleven_turbo_v2', // Faster model for lower latency
          voice_settings: {
            stability: 0.5,
            similarity_boost: 0.75,
            style: 0.0,
            use_speaker_boost: true
          },
          optimize_streaming_latency: 4, // Maximum optimization for speed
          output_format: 'mp3_44100_64' // Lower quality for faster streaming
        })
      });

      if (!response.ok) {
        throw new Error(`ElevenLabs API error: ${response.statusText}`);
      }

      // Create audio from response
      const audioData = await response.arrayBuffer();
      const audioBlob = new Blob([audioData], { type: 'audio/mpeg' });
      const audioUrl = URL.createObjectURL(audioBlob);

      const audio = new Audio(audioUrl);
      audioRef.current = audio; // Store audio reference
      globalAudioTracker.currentAudio = audio; // Register with global tracker

      // Preload audio immediately
      audio.load();

      // Real-time transcription sync with actual audio playback
      const updateTranscription = () => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) return;
        if (!audio.duration || audio.paused || audio.ended) return;

        // Calculate current word index based on actual audio time
        const progress = audio.currentTime / audio.duration;
        const currentIndex = Math.floor(progress * words.length);

        if (currentIndex < words.length) {
          setWordIndex(currentIndex);
          // Show last 15 words for 2-line display
          const displayWords = words.slice(Math.max(0, currentIndex - 15), currentIndex + 1);
          setCurrentText(displayWords.join(' '));
        }
      };

      audio.onloadedmetadata = () => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) {
          audio.pause();
          audio.src = '';
          return;
        }
        // Once we have the duration, we can play
        isInitializingRef.current = false; // Audio loaded, no longer initializing
      };

      audio.oncanplay = () => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) {
          audio.pause();
          audio.src = '';
          return;
        }
        // Audio is ready to play
        setIsLoading(false);
      };

      audio.onplay = () => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) {
          audio.pause();
          audio.src = '';
          return;
        }
        setIsPlaying(true);
        setIsLoading(false);
        setCurrentText('');
        triggerLottieAnimation(true);
        // Update transcription every 50ms for smooth real-time sync
        transcriptionIntervalRef.current = setInterval(updateTranscription, 50);
      };

      audio.onpause = () => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) return;

        if (transcriptionIntervalRef.current) {
          clearInterval(transcriptionIntervalRef.current);
          transcriptionIntervalRef.current = null;
        }
      };

      audio.onended = () => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) {
          URL.revokeObjectURL(audioUrl);
          return;
        }

        if (transcriptionIntervalRef.current) {
          clearInterval(transcriptionIntervalRef.current);
          transcriptionIntervalRef.current = null;
        }
        URL.revokeObjectURL(audioUrl);
        audioRef.current = null;
        setIsPlaying(false);
        setHasPlayed(true);
        setCurrentText('');
        setWordIndex(0);
        triggerLottieAnimation(false);
        if (onComplete) {
          onComplete();
        }
      };

      audio.onerror = (event) => {
        // Check if this audio instance is still valid
        if (currentInstanceId !== audioInstanceIdRef.current) {
          URL.revokeObjectURL(audioUrl);
          return;
        }

        if (transcriptionIntervalRef.current) {
          clearInterval(transcriptionIntervalRef.current);
          transcriptionIntervalRef.current = null;
        }
        URL.revokeObjectURL(audioUrl);
        audioRef.current = null;
        isInitializingRef.current = false; // Reset on error
        setIsPlaying(false);
        setIsLoading(false);

        // Only fallback to browser TTS if this wasn't an intentional stop
        if (!intentionalStopRef.current) {
          synthesizeSpeechBrowser(text);
        }
      };

      // Check if still valid before playing
      if (currentInstanceId !== audioInstanceIdRef.current) {
        audio.src = '';
        URL.revokeObjectURL(audioUrl);
        isInitializingRef.current = false;
        return false;
      }

      console.log('üé§ AIVoiceAgent: Playing audio...');
      await audio.play();
      console.log('üé§ AIVoiceAgent: Audio playing successfully!');
      return true;
    } catch (error) {
      console.error('üé§ AIVoiceAgent: Error in ElevenLabs synthesis:', error);
      isInitializingRef.current = false; // Reset on error
      setIsLoading(false);
      setIsPlaying(false);

      // Only fallback to browser TTS if this wasn't an intentional stop
      if (!intentionalStopRef.current) {
        console.log('üé§ AIVoiceAgent: Falling back to browser TTS...');
        return synthesizeSpeechBrowser(text);
      }
      return false;
    }
  };

  // Fallback: Synthesize speech using Web Speech API
  const synthesizeSpeechBrowser = (text: string) => {
    console.log('üé§ AIVoiceAgent: Using browser TTS fallback');

    if ('speechSynthesis' in window) {
      // Cancel any ongoing speech
      window.speechSynthesis.cancel();

      // Reset intentional stop flag when starting browser TTS
      intentionalStopRef.current = false;

      const utterance = new SpeechSynthesisUtterance(text);
      browserUtteranceRef.current = utterance; // Store reference
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      utterance.volume = 1.0;

      // Try to select a good quality voice
      const voices = window.speechSynthesis.getVoices();
      const preferredVoice = voices.find(voice =>
        voice.name.includes('Google') ||
        voice.name.includes('Microsoft') ||
        voice.name.includes('Samantha') ||
        voice.name.includes('Alex')
      );
      if (preferredVoice) {
        utterance.voice = preferredVoice;
      }

      // Track word boundaries for live transcription
      let currentWordIndex = 0;
      utterance.onboundary = (event) => {
        if (event.name === 'word') {
          const charIndex = event.charIndex;
          const spokenText = text.substring(0, charIndex);
          currentWordIndex = spokenText.split(' ').filter(w => w.length > 0).length;
          setWordIndex(currentWordIndex);

          // Show current sentence (last 15 words for 2-line display)
          const displayWords = words.slice(Math.max(0, currentWordIndex - 15), currentWordIndex + 1);
          setCurrentText(displayWords.join(' '));
        }
      };

      utterance.onstart = () => {
        setIsPlaying(true);
        setCurrentText('');
        setWordIndex(0);
        triggerLottieAnimation(true);
      };

      utterance.onend = () => {
        browserUtteranceRef.current = null;
        setIsPlaying(false);
        setHasPlayed(true);
        setCurrentText('');
        setWordIndex(0);
        triggerLottieAnimation(false);
        if (onComplete) {
          onComplete();
        }
      };

      utterance.onerror = (event) => {
        browserUtteranceRef.current = null;
        setIsPlaying(false);
      };

      window.speechSynthesis.speak(utterance);
      return true;
    }
    return false;
  };

  // Play/Pause functionality - wrapped in useCallback to prevent recreation
  const togglePlayback = useCallback(() => {
    console.log('üéØüéØüéØ AIVoiceAgent v4.0: togglePlayback clicked! isPlaying:', isPlaying);
    console.log('üéØüéØüéØ AIVoiceAgent v4.0: This will play ONLY ElevenLabs audio!');
    if (isPlaying) {
      console.log('üéØüéØüéØ AIVoiceAgent v4.0: Stopping audio...');
      stopAudio();
    } else {
      console.log('üéØüéØüéØ AIVoiceAgent v4.0: Starting ElevenLabs synthesis...');
      synthesizeSpeechElevenLabs(message);
    }
  }, [isPlaying, message]);

  // Stop any existing audio on mount and cleanup on unmount
  useEffect(() => {
    // On mount: stop any audio that might be playing from previous pages
    // Use global tracker to stop ALL audio from any page
    globalAudioTracker.stopAll();

    // Also call local stopAudio
    stopAudio();

    // Cleanup on unmount
    return () => {
      // Stop global audio
      globalAudioTracker.stopAll();

      // Stop local audio
      stopAudio();

      // Extra aggressive cleanup for navigation
      if (audioRef.current) {
        try {
          audioRef.current.pause();
          audioRef.current.src = '';
          audioRef.current = null;
        } catch (e) {
        }
      }

      // Force cancel browser TTS multiple times
      if (window.speechSynthesis) {
        for (let i = 0; i < 10; i++) {
          setTimeout(() => window.speechSynthesis.cancel(), i * 50);
        }
      }
    };
  }, []);

  // Load Lottie animation data
  useEffect(() => {
    fetch('/robot-bot-animation.json')
      .then(response => {
        if (!response.ok) {
          throw new Error(`HTTP error! status: ${response.status}`);
        }
        return response.json();
      })
      .then(data => {
        setAnimationData(data);
      })
      .catch(error => {
      });
  }, []);

  // Auto-play after mount
  useEffect(() => {
    console.log('üéµ AIVoiceAgent v4.0 AUTO-PLAY CHECK:', {
      autoPlay,
      hasPlayed,
      isVisible,
      isPlaying,
      isLoading
    });

    if (autoPlay && !hasPlayed && isVisible && !isPlaying && !isLoading) {
      console.log('üéµüéµüéµ AIVoiceAgent v4.0: AUTO-PLAY TRIGGERED! Starting ElevenLabs in 100ms...');
      // Small delay to ensure mount cleanup completes
      const timer = setTimeout(() => {
        console.log('üéµüéµüéµ AIVoiceAgent v4.0: NOW PLAYING ELEVENLABS AUDIO!');
        synthesizeSpeechElevenLabs(message);
      }, 100);

      return () => clearTimeout(timer);
    } else {
      console.log('‚ùå AIVoiceAgent v4.0: AUTO-PLAY SKIPPED. Reason:',
        !autoPlay ? 'autoPlay=false' :
        hasPlayed ? 'already played' :
        !isVisible ? 'not visible' :
        isPlaying ? 'already playing' :
        isLoading ? 'loading' : 'unknown');
    }
  }, [autoPlay, hasPlayed, message, isVisible, isPlaying, isLoading]);

  // Reset visibility when message changes (e.g., when navigating to different page)
  useEffect(() => {
    console.log('üîÑ AIVoiceAgent: Message changed, resetting visibility to true');
    setIsVisible(true);
    setHasPlayed(false); // Also reset hasPlayed so autoPlay can work again
  }, [message]);

  console.log('üîç AIVoiceAgent: About to check visibility. isVisible =', isVisible);

  if (!isVisible) {
    console.log('‚ùå AIVoiceAgent: NOT VISIBLE - returning null!');
    return null;
  }

  console.log('‚úÖ AIVoiceAgent: IS VISIBLE - rendering component');

  return (
    <AnimatePresence>
      <motion.div
        initial={{ opacity: 0, scale: 0.5 }}
        animate={{
          opacity: 1,
          scale: 1
        }}
        exit={{ opacity: 0, scale: 0.5 }}
        transition={{ type: 'spring', duration: 0.6, bounce: 0.4 }}
        className={`fixed ${positionClasses[position]} z-[999999]`}
        onMouseEnter={() => setShowTooltip(true)}
        onMouseLeave={() => setShowTooltip(false)}
      >
        <div className="relative group">
          {/* Loading indicator */}
          {isLoading && (
            <motion.div
              className="absolute inset-0 rounded-full bg-blue-400/40"
              animate={{
                scale: [1, 1.3, 1],
                opacity: [0.5, 0.8, 0.5],
              }}
              transition={{
                duration: 1.5,
                repeat: Infinity,
                ease: "easeInOut"
              }}
            />
          )}

          {/* Pulsing rings when speaking */}
          {isPlaying && !isLoading && (
            <>
              <motion.div
                className="absolute inset-0 rounded-full bg-brand-primary/30"
                animate={{
                  scale: [1, 1.4, 1],
                  opacity: [0.6, 0, 0.6],
                }}
                transition={{
                  duration: 2,
                  repeat: Infinity,
                  ease: "easeOut"
                }}
              />
              <motion.div
                className="absolute inset-0 rounded-full bg-brand-secondary/40"
                animate={{
                  scale: [1, 1.6, 1],
                  opacity: [0.5, 0, 0.5],
                }}
                transition={{
                  duration: 2.5,
                  repeat: Infinity,
                  ease: "easeOut",
                  delay: 0.3
                }}
              />
            </>
          )}

          {/* Main Lottie Animation Container */}
          <motion.div
            className="relative w-40 h-40 rounded-full overflow-hidden shadow-2xl cursor-pointer"
            style={{
              background: 'radial-gradient(circle at center, #B4A7FF 0%, #9B8FE8 40%, #7D6FD3 100%)'
            }}
            whileHover={{ scale: 1.08 }}
            whileTap={{ scale: 0.95 }}
            onClick={togglePlayback}
          >
            {animationData ? (
              <Lottie
                lottieRef={lottieRef}
                animationData={animationData}
                loop={true}
                autoplay={true}
                style={{
                  width: '100%',
                  height: '100%',
                  position: 'absolute',
                  top: 0,
                  left: 0,
                  zIndex: 10,
                  pointerEvents: 'none'
                }}
                rendererSettings={{
                  preserveAspectRatio: 'xMidYMid meet'
                }}
              />
            ) : (
              <div className="w-full h-full flex items-center justify-center">
                <Bot className="w-16 h-16 text-purple-300 animate-pulse" />
              </div>
            )}

            {/* Animated border when speaking */}
            {isPlaying && (
              <motion.div
                className="absolute inset-0 rounded-full border-4 border-white/60"
                animate={{
                  rotate: 360,
                }}
                transition={{
                  duration: 4,
                  repeat: Infinity,
                  ease: "linear"
                }}
              />
            )}

            {/* Sound wave effect overlay */}
            {isPlaying && (
              <div className="absolute bottom-2 left-1/2 transform -translate-x-1/2 flex items-end gap-1">
                {[0, 1, 2, 3, 4].map((i) => (
                  <motion.div
                    key={i}
                    className="w-1 bg-white/90 rounded-full shadow-lg"
                    animate={{
                      height: [8, 20, 8],
                    }}
                    transition={{
                      duration: 0.6,
                      repeat: Infinity,
                      delay: i * 0.1,
                    }}
                  />
                ))}
              </div>
            )}
          </motion.div>

          {/* Close button (appears on hover) */}
          <motion.button
            initial={{ opacity: 0, scale: 0 }}
            animate={{
              opacity: showTooltip ? 1 : 0,
              scale: showTooltip ? 1 : 0
            }}
            transition={{ duration: 0.2 }}
            onClick={(e) => {
              e.stopPropagation();
              stopAudio();
              setIsVisible(false);
            }}
            className="absolute -top-2 -right-2 w-6 h-6 bg-red-500 hover:bg-red-600 text-white rounded-full flex items-center justify-center shadow-lg"
          >
            <X className="w-3 h-3" />
          </motion.button>

          {/* Tooltip */}
          <AnimatePresence>
            {showTooltip && !isPlaying && (
              <motion.div
                initial={{ opacity: 0, y: 10 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: 10 }}
                className="absolute bottom-full left-1/2 transform -translate-x-1/2 mb-2 px-3 py-2 bg-gray-900 text-white text-xs rounded-lg whitespace-nowrap shadow-xl"
              >
                {hasPlayed ? 'Click to replay' : 'Click to play'}
                <div className="absolute top-full left-1/2 transform -translate-x-1/2 -mt-1">
                  <div className="border-4 border-transparent border-t-gray-900"></div>
                </div>
              </motion.div>
            )}
          </AnimatePresence>

          {/* Transcription Box - Hidden */}
          {/* <AnimatePresence>
            {(isPlaying || isLoading || currentText) && (
              <motion.div
                initial={{ opacity: 0, y: 10 }}
                animate={{ opacity: 1, y: 0 }}
                exit={{ opacity: 0, y: 10 }}
                transition={{ duration: 0.3 }}
                className="absolute bottom-full mb-3 right-0 w-56"
              >
                <div className="bg-white dark:bg-gray-800 rounded-xl shadow-2xl border-2 border-brand-primary/20 p-3 backdrop-blur-sm">
                  <div className="flex items-center gap-2 mb-2">
                    <motion.div
                      className={`w-2 h-2 rounded-full ${isLoading ? 'bg-blue-500' : 'bg-red-500'}`}
                      animate={{ opacity: [1, 0.3, 1] }}
                      transition={{ duration: 1.5, repeat: Infinity }}
                    />
                    <span className="text-xs font-medium text-gray-600 dark:text-gray-400">
                      {isLoading ? 'Loading AI Voice...' : 'AI Speaking'}
                    </span>
                  </div>

                  <div className="text-sm text-gray-800 dark:text-gray-200 leading-relaxed overflow-hidden"
                       style={{
                         display: '-webkit-box',
                         WebkitLineClamp: 2,
                         WebkitBoxOrient: 'vertical',
                         minHeight: '2.5rem'
                       }}>
                    {isLoading ? 'Preparing audio...' : (currentText || 'Starting...')}
                  </div>

                  {!isLoading && (
                    <div className="mt-2 h-1 bg-gray-200 dark:bg-gray-700 rounded-full overflow-hidden">
                      <motion.div
                        className="h-full bg-gradient-to-r from-brand-primary to-brand-secondary"
                        initial={{ width: '0%' }}
                        animate={{ width: `${(wordIndex / words.length) * 100}%` }}
                        transition={{ duration: 0.1 }}
                      />
                    </div>
                  )}

                  {isLoading && (
                    <div className="mt-2 h-1 bg-gray-200 dark:bg-gray-700 rounded-full overflow-hidden">
                      <motion.div
                        className="h-full bg-gradient-to-r from-blue-400 to-blue-600"
                        animate={{ width: ['0%', '100%'] }}
                        transition={{ duration: 2, repeat: Infinity, ease: 'linear' }}
                      />
                    </div>
                  )}
                </div>
              </motion.div>
            )}
          </AnimatePresence> */}
        </div>
      </motion.div>
    </AnimatePresence>
  );
});
